![image](https://github.com/ai-agi/LLMs-Enhanced-Long-Text-Generation-Survey/assets/149247430/b1f8daec-8023-4396-a02a-104f3fc3d2ae)# LLMs-Enhanced-Long-Text-Generation-Survey

Long Form NLG Generation  Based on Large Language Models

# **Resource**

  ## A. Task Perspective

  ### _A.1 Long Form Open Domain Dialogue_

  1. MemoChat: Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain Conversation. _Junru Lu, Siyu An, Mingbao Lin, Gabriele Pergola, Yulan He, Di Yin, Xing Sun, Yunsheng Wu._ [\[pdf\]](https://arxiv.org/pdf/2308.08239.pdf). `Arxiv Aug 16, 2023`.
  2. Prompted LLMs as Chatbot Modules for Long Open-domain Conversation. _Gibbeum Lee，Volker Hartmann， Jongho Park，Dimitris Papailiopoulos, Kangwook Lee._ [\[pdf\]](https://aclanthology.org/2023.findings-acl.277.pdf). `Findings of ACL 2023`.

  ### _A.2 Long Dialogue Summarization_



  ### _A.3 Long Document Summarization_



  ### _A.4 Long-Form Narrative Text_
 
  1. EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation.Wang You, WenshanWu, Yaobo Liang, Shaoguang Mao, Chenfei Wu, Maosong Cao, Yuzhe Cai, Yiduo Guo, Yan Xia, Furu Wei, Nan Duan, [[pdf]](https://arxiv.org/pdf/2310.08185.pdf).`Arxiv 12 Oct 2023`.

  ### _A.5 Commensense Story_
  
 1. A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation.Jian Guan, Fei Huang, Zhihao Zhao, Xiaoyan Zhu, Minlie Huang, [[pdf]](https://aclanthology.org/2020.tacl-1.7.pdf)`tacl 1 Jan 2020`

  ## B. Constraints Perspective

  1. Fixed global memory for controllable long text generation. _Zheng Chen, Zhejun Liu._ [\[pdf\]](https://dl.acm.org/doi/abs/10.1007/s10489-022-04197-6). `Applied Intelligence, 2022`.

  ## C. Technique Perspective

  ### C.1 Data Augmentation

  1. Data augmentation in natural language processing: a novel text generation approach for long and short text classifers.Markus Bayer1  · Marc‑André Kaufhold1 · Björn Buchhold2 ·   Marcel Keller3 · Jörg Dallmeyer2 · Christian Reuter1 [[pdf]](https://link.springer.com/content/pdf/10.1007/s13042-022-01553-3.pdf?pdf=button) `International Journal of Machine       Learning and Cybernetics (2023)`

  ### C.2 Detector

  1. A Survey on LLM-generated Text Detection: Necessity, Methods, and Future Directions.Junchao Wu, Shu Yang, Runzhe Zhan, Yulin Yuan, Derek F. Wong Senior Member, IEEE and Lidia S. Chao Member, IEEE. [[pdf]](https://arxiv.org/pdf/2310.14724.pdf) `Arxiv Oct 24, 2023`

  ### C.3 LongForm

  1. LongForm: Optimizing Instruction Tuning for Long Text Generation with Corpus Extraction.Abdullatif Köksal, Timo Schick, Anna Korhonen, Hinrich Schütze [[pdf]](https://arxiv.org/abs/2304.08460) `arxiv *17 Apr 2023*`

  ### C.4 Language Models

  1. A Survey of Large Language Models.Wayne Xin Zhao, Kun Zhou, Junyi Li,  [[pdf]](https://arxiv.org/abs/2303.18223) `arxiv *31 Mar 2023*`
  2. Long and Diverse Text Generation with Planning-based Hierarchical Variational Model.Zhihong Shao, Minlie Huang, Jiangtao Wen, Wenfei Xu, Xiaoyan Zhu,  [[pdf]](https://arxiv.org/pdf/1908.06605.pdf)`arxiv *25 Aug 2019*`
  3. Long Text Generation by Modeling Sentence-Level and Discourse-Level Coherence.Jian Guan, Xiaoxi Mao, Changjie Fan, Zitao Liu, Wenbiao Ding, and Minlie Huang, [[pdf]](https://arxiv.org/pdf/2105.08963.pdf)`arxiv 19 May 2021`
  4. Coherent Long Text Generation by Contrastive Soft Prompt.Guandan Chen, Jiashu Pu, Yadong Xi, Rongsheng Zhang, [[pdf]](https://aclanthology.org/2022.gem-1.42.pdf)`acl 7 Dec 2022`
  5. A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation.Jian Guan, Fei Huang, Zhihao Zhao, Xiaoyan Zhu, Minlie Huang, [[pdf]](https://aclanthology.org/2020.tacl-1.7.pdf)`tacl 1 Jan 2020`
  6. LongT5 Efficient Text-To-Text Transformer for Long Sequences


  









